{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing All Necesssary Packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import requests, shutil\n",
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "new_size = (256, 256)\n",
    "bin_n = 16\n",
    "#Defining Functions\n",
    "#Download Data & Preprpcessing Functions:\n",
    "def download_prep(im_info,loc):\n",
    "    #Load the data from URL, save and resize the image to specific aspect ratio. \n",
    "    #Images are saved seperately into Train and test data folders\n",
    "    try:\n",
    "        response=requests.get(im_info.iloc[1], stream=True)\n",
    "        open('./Resized_image1/'+str(im_info.iloc[0])+'.jpg','wb').write(response.content)\n",
    "        img1 = io.imread('./Resized_image1/'+str(im_info.iloc[0])+'.jpg')\n",
    "        io.imsave('./Resized_image/'+str(loc)+'/'+str(im_info.iloc[0])+'.jpg',img_as_ubyte(np.array(resize(img1,new_size,mode='reflect', anti_aliasing = True,anti_aliasing_sigma=None))))\n",
    "        os.remove('./Resized_image1/'+str(im_info.iloc[0])+'.jpg')\n",
    "    except:\n",
    "        print(im_info.iloc[0]) #Errored out image id is displayed in console plus you can check in resized_image1 folder\n",
    "\n",
    "#Feature Extractor - HOG Extractor\n",
    "def hog(img):\n",
    "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)\n",
    "    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)\n",
    "    bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]\n",
    "    mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist = np.hstack(hists)     # hist is a 64 bit vector\n",
    "    return hist\n",
    "\n",
    "#Load data\n",
    "train  = pd.read_csv(\"./train.csv\")\n",
    "#Frequency Count of each Landmark\n",
    "val = train[\"landmark_id\"].value_counts()\n",
    "#Frq = train.groupby(\"landmark_id\").count().sort_values(\"id\", ascending=False)\n",
    "#Frq[\"id\"].iloc[:10]\n",
    "val = pd.DataFrame(val)\n",
    "val[\"Landmark_id\"] = val.index\n",
    "val = val.reset_index(drop = True)\n",
    "val = val.rename(columns = {\"Landmark_id\" : \"Landmark_id\",\"landmark_id\" : \"Frequency\"})\n",
    "#Fetching top 10 Sampled Landmark details\n",
    "top_10_landmark_id = list(val.iloc[0:10,][\"Landmark_id\"])\n",
    "top_df = pd.DataFrame()\n",
    "top_df = train[train[\"landmark_id\"].isin(top_10_landmark_id)]  \n",
    "top_df = top_df.reset_index(drop = True)\n",
    "#Split the dataset to Train & Test - 0.7 to 0.8 Ratio\n",
    "xTrain, xTest = train_test_split(top_df, test_size = 0.3, random_state = 0)\n",
    "#Download Data:\n",
    "#Train Dataset:\n",
    "for i in range(len(xTrain)):\n",
    "    if (i % 100 == 0):\n",
    "        print( i , (time.time() - start_time))\n",
    "    im_info = xTrain.iloc[i] \n",
    "    loc = \"Train_image\"\n",
    "    download_prep(im_info,loc)\n",
    "#Test Dataset\n",
    "for i in range(len(xTest)):\n",
    "    if (i % 100 == 0):\n",
    "        print( i , (time.time() - start_time))\n",
    "    im_info = xTest.iloc[i] \n",
    "    loc = \"Test_image\"\n",
    "    download_prep(im_info,loc)\n",
    "#Feature Extraction for Train and test dataset\n",
    "#Xtrain:\n",
    "for i in range(len(xTrain)):\n",
    "    im_info_train = xTrain.iloc[i]\n",
    "    try:\n",
    "        if os.path.exists('./Resized_image/Train_image/'+str(im_info_train.iloc[0])+'.jpg'):\n",
    "            his = hog(io.imread('./Resized_image/Train_image/'+str(im_info_train.iloc[0])+'.jpg'))\n",
    "            train_feature.append(his)\n",
    "            train_labels.append(im_info_train.iloc[2])\n",
    "    except:\n",
    "        print(\"Train \", im_info_train.iloc[0])\n",
    "#XTest\n",
    "for i in range(len(xTest)):\n",
    "    im_info_test = xTest.iloc[i]\n",
    "    try:\n",
    "        if os.path.exists('./Resized_image/Test_image/'+str(im_info_test.iloc[0])+'.jpg'):\n",
    "            his = hog(io.imread('./Resized_image/Test_image/'+str(im_info_test.iloc[0])+'.jpg'))\n",
    "            test_feature.append(his)\n",
    "            test_labels.append(im_info_test.iloc[2])\n",
    "    except:\n",
    "        print(\"Test \",im_info_test.iloc[0])\n",
    "#Converting to an Numpy Array\n",
    "#Train image\n",
    "train_feature_data = np.float32(train_feature)\n",
    "train_label_data = np.float32(train_labels)\n",
    "#Test image\n",
    "test_feature_data = np.float32(test_feature)\n",
    "test_label_data = np.float32(test_labels)\n",
    "#Modelling\n",
    "seed = 100\n",
    "n_trees = 100\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=seed, solver='lbfgs', multi_class='multinomial',max_iter = 1000)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=n_trees, random_state=seed)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM Non Linear', SVC(random_state=seed, kernel='rbf', max_iter = 1000, C = 0.1, gamma = 0.0001)))\n",
    "models.append(('SVM Linear',SVC(kernel='linear', max_iter = 1000)))\n",
    "#Cross Validation\n",
    "scoring    = \"accuracy\"\n",
    "accuracy_score = []\n",
    "classifier = []\n",
    "for classfr, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_value = cross_val_score(model, train_feature_data,train_label_data, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_value)\n",
    "    classifier.append(classfr)\n",
    "    Score = \"%s: %f\" % (classfr, cv_value.mean())\n",
    "    print(Score)\n",
    "#Prediction on Test Set:\n",
    "#Logistic Regression\n",
    "mlg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',max_iter = 1000)\n",
    "lg_clf = mlg.fit(train_feature_data,train_label_data)\n",
    "pred_lg = lg_clf.predict(test_feature_data)\n",
    "acc = accuracy_score(test_label_data, pred_lg) * 100\n",
    "conf_matrix = confusion_matrix(test_label_data, pred_lg)\n",
    "test_label_data_val = test_label_data.astype(\"str\")\n",
    "class_names = np.unique(test_label_data)\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names )\n",
    "print(\"Logistic Regression results\")\n",
    "print(\"Accuracy\")\n",
    "print(acc)\n",
    "print(\"Confusion Matrix\")\n",
    "print(df_cm)\n",
    "#SVM_Linear Modeling\n",
    "svm_clf = SVC(kernel='linear', max_iter = 1000)\n",
    "svm_clf.fit(train_feature_data,train_label_data)\n",
    "pred_svml = svm_clf.predict(test_feature_data)\n",
    "acc = accuracy_score(test_label_data, pred_svml) * 100\n",
    "conf_matrix = confusion_matrix(test_label_data, pred_svml)\n",
    "test_label_data_val = test_label_data.astype(\"str\")\n",
    "class_names = np.unique(test_label_data_val)\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names )\n",
    "print(\"SVM Linear Kernel results\")\n",
    "print(\"Accuracy\")\n",
    "print(acc)\n",
    "print(\"Confusion Matrix\")\n",
    "print(df_cm)\n",
    "#SVM_Non_Linear Modeling\n",
    "svm_clf = SVC(kernel='rbf', max_iter = 1000, C = 0.1, gamma = 0.0001)\n",
    "svm_clf.fit(train_feature_data,train_label_data)\n",
    "pred_svmnl = svm_clf.predict(test_feature_data)\n",
    "acc = accuracy_score(test_label_data, pred_svmnl) * 100\n",
    "conf_matrix = confusion_matrix(test_label_data, pred_svmnl)\n",
    "test_label_data_val = test_label_data.astype(\"str\")\n",
    "class_names = np.unique(test_label_data_val)\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names )\n",
    "print(\"SVM Non Linear Kernel results\")\n",
    "print(\"Accuracy\")\n",
    "print(acc)\n",
    "print(\"Confusion Matrix\")\n",
    "print(df_cm)\n",
    "#Random Forest Classfier\n",
    "model_rf = RandomForestClassifier(n_estimators=500)\n",
    "model_rf.fit(train_feature_data,train_label_data)\n",
    "pred_rf = model_rf.predict(test_feature_data)\n",
    "acc = accuracy_score(test_label_data, pred_rf) * 100\n",
    "conf_matrix = confusion_matrix(test_label_data, pred_rf)\n",
    "test_label_data_val = test_label_data.astype(\"str\")\n",
    "class_names = np.unique(test_label_data)\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names )\n",
    "print(\"Random Forest results\")\n",
    "print(\"Accuracy\")\n",
    "print(acc)\n",
    "print(\"Confusion Matrix\")\n",
    "print(df_cm)\n",
    "#Decision Tree Classifier\n",
    "model_DT = DecisionTreeClassifier(random_state=seed)\n",
    "model_DT.fit(train_feature_data,train_label_data)\n",
    "pred_DT = model_DT.predict(test_feature_data)\n",
    "acc = accuracy_score(test_label_data, pred_DT) * 100\n",
    "conf_matrix = confusion_matrix(test_label_data, pred_DT)\n",
    "test_label_data_val = test_label_data.astype(\"str\")\n",
    "class_names = np.unique(test_label_data)\n",
    "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names )\n",
    "print(\"Decision Tree results\")\n",
    "print(\"Accuracy\")\n",
    "print(acc)\n",
    "print(\"Confusion Matrix\")\n",
    "print(df_cm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
